---
title: "03OCT24_EDA"
author: "Stella Koo"
date: "2024-10-03"
output: github_document
---
## Explatory Data Analysis (EDA)
Analyze and investigate data sets and summarize their main characteristics, often employing data visualization methods. Discover patterns, spot anomalies, test a hypothesis, or check assumptions.

* Conduct EDA using `dplyr` verbs (`group_by` and `summarize`)

`rnoaa::meteo_pull_monitors()` pulls weather data from National Oceanic and Atmospheric Administration database (NOAA) for a list of weather stations. 
```{r message = FALSE}
library(tidyverse)

weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728", "USW00022534", "USS0023B17S"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2021-01-01",
    date_max = "2022-12-31") |>
  mutate(
    name = case_match(
      id, 
      "USW00094728" ~ "CentralPark_NY", 
      "USW00022534" ~ "Molokai_HI",
      "USS0023B17S" ~ "Waterhole_WA"),
    tmin = tmin / 10,
    tmax = tmax / 10,
    month = lubridate::floor_date(date, unit = "month")) |>
  select(name, id, everything())
```

### Initial Numeric Explorations
```{r warning = FALSE}
weather_df |> 
  ggplot(aes(x = prcp)) + 
  geom_histogram()
```

Very skewed distribution. Majority of days have no precipitation. Examining the relatively few days have very high precipitation might be helpful.

```{r}
weather_df |> 
  filter(prcp >= 1000)
```

```{r}
weather_df |> 
  filter(tmax >= 20, tmax <= 30) |> 
  ggplot(aes(x = tmin, y = tmax, color = name, shape = name)) + 
  geom_point(alpha = .75)
```

The previous scatterplot shows that Central Park and Molokai report temperature values differently from Waterhole.

### `group_by`
Only using `group_by()` without a function like `summarize()`, `mutate()`, or `filter()`, it won't change or reduce the data. The data will be grouped internally, but all the rows will still be displayed.

* `ungroup()` will remove groups.

```{r}
weather_df |>
  group_by(name, month)
```

### Counting things
#### `group_by()` and `summarize()`
Counting number of observations in each location in the complete dataset:

```{r}
weather_df |>
  group_by(name) |>
  summarize(n_obs = n())
```

Can group by more than one variable (e.g each location and month):

* `n()` counts number of rows.

```{r}
weather_df |>
  group_by(name, month) |>
  summarize(n_obs = n()) 
```

Can compute multiple summaries within each group:
```{r}
weather_df |>
  group_by(month) |>
  summarize(
    n_obs = n(),
    n_days = n_distinct(date))
```

To tabulate the frequency of a binary outcome across levels of a binary predictor:

* E.g. Number of cold and not-cold days in Central Park and Waterhole.

```{r}
weather_df |> 
  drop_na(tmax) |> 
  mutate(
    cold = case_when(
      tmax <  5 ~ "cold",
      tmax >= 5 ~ "not_cold",
      TRUE      ~ ""
  )) |> 
  filter(name != "Molokai_HI") |> 
  group_by(name, cold) |> 
  summarize(count = n())
```

Can also re-organize into a more standard (non-tidy) 2x2 table using `pivot_wider` or `janitor::tabyl`:
```{r}
weather_df |> 
  drop_na(tmax) |> 
  mutate(cold = case_when(
    tmax <  5 ~ "cold",
    tmax >= 5 ~ "not_cold",
    TRUE     ~ ""
  )) |> 
  filter(name != "Molokai_HI") |> 
  janitor::tabyl(name, cold)
```


#### `count()`
Can also use `count()` instead of `group_by()` and `summarize()`:

* Creates a dataframe that can be manipulated directly.

```{r}
weather_df |>
  count(month, name)
```

```{r}
weather_df |>
  count(month, name = "n_obs")
```

#### `table()` function
Base R's `table` function also produces summaries. table`’s output is of class table and is hard to do any additional work with.
```{r}
weather_df |>
  pull(month) |>
  table()
```

### General Summaries
Standard statistical summaries are regularly computed in `summarize()` using functions like `mean()`, `median()`, `var()`, `sd()`, `mad()`, `IQR()`, `min()`, and `max()`. To use these, indicate the variable to which they apply and include any additional arguments as necessary.

```{r}
weather_df |>
  group_by(month) |>
  summarize(
    mean_tmax = mean(tmax, na.rm = TRUE),
    mean_prec = mean(prcp, na.rm = TRUE),
    median_tmax = median(tmax),
    sd_tmax = sd(tmax))
```

If want to summarize multiple columns using the same summary, the `across` function is helpful:
```{r}
weather_df |>
  group_by(name, month) |>
  summarize(across(tmin:prcp, mean))
```

Can also incorporate grouping and summarizing within broader analysis pipelines. E.g. can create a plot based on monthly summary:

```{r}
weather_df |>
  group_by(name, month) |>
  summarize(mean_tmax = mean(tmax, na.rm = TRUE)) |>
  ggplot(aes(x = month, y= mean_tmax, color = name)) +
  geom_point() + geom_line() +
  theme(legend.position = "bottom")
```

`knitr::kable()` function creates a more human-readable table for reporting. 

* The `digits` argument controls number of decimal places displayed for numeric values.

```{r}
weather_df |>
  group_by(name, month) |>
  summarize(mean_tmax = mean(tmax, na.rm = TRUE)) |> 
  pivot_wider(
    names_from = name,
    values_from = mean_tmax) |> 
  knitr::kable(digits = 1)
```

### Grouped `mutate`
Summarizing collapses groups into single data points. In contrast, using `mutate()` in conjuntion with `group_by()` will retain all original data points and add new variables computed within groups.

* E.g. Compare daily max temperature to the annual average max temperature for each station separately:

```{r warning = FALSE}
weather_df |>
  group_by(name) |>
  mutate(
    mean_tmax = mean(tmax, na.rm = TRUE),
    centered_tmax = tmax - mean_tmax) |> 
  ggplot(aes(x = date, y = centered_tmax, color = name)) + 
    geom_point() 
```

### Window functions
Window functions take `n` inputs and return `n` outputs, and the outputs depend on all the inputs.

* Most likely to need ranking functions and offsets.

Find the max temperature ranking within month. This sort of ranking is useful when filtering data based on rank. We could, for example, keep only the day with the lowest max temperature within each month:

```{r}
weather_df |>
  group_by(name, month) |>
  mutate(temp_ranking = min_rank(tmax)) |>
  select(temp_ranking, everything())
```

```{r}
weather_df |>
  group_by(name, month) |>
  filter(min_rank(tmax) < 2) 
```

* Offsets, especially lags, are used to compare an observation to it’s previous value. This is useful, for example, to find the day-by-day change in max temperature within each station over the year:
  * `lag(tmax)` is the tmax from the previous day.

```{r}
weather_df |>
  group_by(name) |>
  mutate(temp_change = tmax - lag(tmax))
```

```{r}
weather_df |>
  group_by(name) |>
  mutate(temp_change = tmax - lag(tmax)) |>
  summarize(
    temp_change_sd = sd(temp_change, na.rm = TRUE),
    temp_change_max = max(temp_change, na.rm = TRUE))
```

### Learning Assessment
```{r}
pulse_data = 
  haven::read_sas("./data/public_pulse_data.sas7bdat") |>
  janitor::clean_names() |>
  pivot_longer(
    bdi_score_bl:bdi_score_12m,
    names_to = "visit", 
    names_prefix = "bdi_score_",
    values_to = "bdi") |>
  select(id, visit, everything()) |>
  mutate(
    visit = replace(visit, visit == "bl", "00m"),
    visit = factor(visit, levels = str_c(c("00", "01", "06", "12"), "m"))) |>
  arrange(id, visit)

pulse_data |>
  group_by(visit) |>
  summarize(
    mean_bdi = mean(bdi, na.rm = TRUE),
    median_bdi = median(bdi, na.rm = TRUE))
```

```{r}
pup_data = 
  read_csv("./data/FAS_pups.csv") |>
  janitor::clean_names() |>
  mutate(sex = recode(sex, `1` = "male", `2` = "female")) 

litter_data = 
  read_csv("./data/FAS_litters.csv") |>
  janitor::clean_names() |>
  separate(group, into = c("dose", "day_of_tx"), sep = 3)

fas_data = left_join(pup_data, litter_data, by = "litter_number") 

fas_data |> 
  group_by(dose, day_of_tx) |> 
  drop_na(dose) |> 
  summarize(mean_pivot = mean(pd_pivot, na.rm = TRUE)) |> 
  pivot_wider(
    names_from = dose, 
    values_from = mean_pivot) |> 
  knitr::kable(digits = 3)
```

